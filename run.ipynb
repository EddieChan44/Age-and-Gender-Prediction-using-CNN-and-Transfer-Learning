{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# Data collection\nimport tensorflow as tf\nfrom tensorflow.keras.utils import load_img\nfrom tensorflow.keras.regularizers import l2\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Input, BatchNormalization\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\nimport os\nimport warnings\nfrom tqdm.notebook import tqdm\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\n# Mount google drive\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\n# Data collction\nBASE_DIR = '/content/drive/MyDrive/ML2CW1/train_val'\nage_labels = []\ngender_labels = []\nimage_paths = []\n\nimage_filenames = os.listdir(BASE_DIR)\nrandom.shuffle(image_filenames) # random sequence for training\n\nfor image in tqdm(image_filenames):\n  image_path = os.path.join(BASE_DIR, image)\n  img_components = image.split('_') # Split by \"[age] [gender] [race] [date&time].jpg\"\n  age_label = int(img_components[0])\n  gender_label = int(img_components[1])\n\n  # Append to image list and feature lists in sequence\n  age_labels.append(age_label)\n  gender_labels.append(gender_label)\n  image_paths.append(image_path)\n\nprint(f'No. of images: {len(image_paths)}, No. of gender: {len(gender_labels)}, No. of age: {len(age_labels)}')\n\n# Mapping image path and features\nimport pandas as pd\ndf = pd.DataFrame()\ndf['image_path'], df['age'], df['gender'] = image_paths, age_labels, gender_labels\ndf.head(10)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Visualize data photos\nfrom PIL import Image\nimport seaborn as sns\n\nrand_index = random.randint(0, len(image_paths))# Show random image\nIMG = Image.open(df['image_path'][rand_index])\n\ngender_mapping = {0: 'Male', 1: 'Female'} # Gender mapping\n\n# Plot the image with age and gender information\nplt.figure(figsize=(10, 8))\nplt.subplot(2, 2, 1)\nplt.title(f'Age: {df[\"age\"][rand_index]} Gender: {gender_mapping[df[\"gender\"][rand_index]]}')\nplt.axis('off')\nplt.imshow(IMG)\n\n# Age distribution\nplt.subplot(2, 2, 2)\nsns.distplot(df['age'])\nplt.title('Age Distribution')\n\n# Gender distribution\nplt.subplot(2, 2, 3)\nsns.countplot(df['gender'].map(gender_mapping))\nplt.title('Gender Distribution')\n\ngender_counts = df['gender'].map(gender_mapping).value_counts()\nplt.subplot(2, 2, 4)\nplt.text(0.5, 0.5, f'Male: {gender_counts[\"Male\"]}\\nFemale: {gender_counts[\"Female\"]}', fontsize=12, ha='center')\nplt.axis('off')\n\n\nplt.tight_layout()\nplt.show()\n\n# Showing 20 images\nplt.figure(figsize=(25, 25))\nsamples = df.iloc[0:20]\n\nfor index, sample, age, gender in samples.itertuples():\n    plt.subplot(5, 4, index + 1)\n    img = load_img(sample)\n    img = np.array(img)\n    plt.axis('off')\n    plt.title(f'Age: {age} | Gender: {gender_mapping[gender]} | Image Size: {img.shape[0]}x{img.shape[1]}')\n    plt.imshow(img)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Data rearrangment\ndef extract_image_features(images):\n    features = list()\n\n    for image in tqdm(images):\n        img = load_img(image, target_size=(128, 128))\n        img = img.convert('RGB')\n        img = np.array(img)\n        features.append(img)\n\n    features = np.array(features)\n    return features",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Data pre-processing\nX = extract_image_features(df['image_path'])\n\nX.shape\n\nX = X / 255.0\n\ny_gender = np.array(df['gender'])\ny_age = np.array(df['age'])\n\ninput_shape = (128, 128, 3) # Set input arrays shape\n\nrand_index = random.randint(0, len(X)-1)\n\n# Reshape and plot picked image\nplt.figure(figsize=(5, 5))\nplt.imshow(X[rand_index].reshape(input_shape))\nplt.title(f'Reshaped Image')\nplt.axis('off')\nplt.show()\n\nrandom_image = X[rand_index]\n\n# Showing image size\nprint(f\"Size of the image: {random_image.shape}\")\n\n# Print the number array of the three layers\nprint(\"\\nNumber array of the three layers:\")\nprint(\"Red channel:\")\nprint(random_image[:,:,0])  # Rgb\nprint(\"\\nGreen channel:\")\nprint(random_image[:,:,1])  # rGb\nprint(\"\\nBlue channel:\")\nprint(random_image[:,:,2])  # rgB\n\n# Plot the image in RGB and each channels\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\naxes[0].imshow(random_image[:,:,0], cmap='Reds')\naxes[0].set_title('Red Channel')\naxes[0].axis('off')\n\naxes[1].imshow(random_image[:,:,1], cmap='Greens')\naxes[1].set_title('Green Channel')\naxes[1].axis('off')\n\naxes[2].imshow(random_image[:,:,2], cmap='Blues')\naxes[2].set_title('Blue Channel')\naxes[2].axis('off')\n\nplt.show()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# CNN network building\nfrom tensorflow.keras.optimizers import Adam\n\ninputs = Input((input_shape))\nconv_1 = Conv2D(64, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2(0.001))(inputs)\nmax_1 = MaxPooling2D(pool_size=(2, 2))(conv_1)\nbatch_norm_1 = BatchNormalization()(max_1)\n\nconv_2 = Conv2D(128, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2(0.001))(batch_norm_1)\nmax_2 = MaxPooling2D(pool_size=(2, 2))(conv_2)\nbatch_norm_2 = BatchNormalization()(max_2)\n\nconv_3 = Conv2D(256, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2(0.001))(batch_norm_2)\nmax_3 = MaxPooling2D(pool_size=(2, 2))(conv_3)\nbatch_norm_3 = BatchNormalization()(max_3)\n\nconv_4 = Conv2D(512, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2(0.001))(batch_norm_3)\nmax_4 = MaxPooling2D(pool_size=(2, 2))(conv_4)\nbatch_norm_4 = BatchNormalization()(max_4)\n\nflatten = Flatten()(batch_norm_4)\n\ndense_1 = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(flatten)\ndense_2 = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(flatten)\n\ndropout_1 = Dropout(0.4)(dense_1)\ndropout_2 = Dropout(0.4)(dense_2)\n\noutput_1 = Dense(1, activation='sigmoid', name='gender_out')(dropout_1)\noutput_2 = Dense(1, activation='relu', name='age_out')(dropout_2)\n\nmodelA = Model(inputs=[inputs], outputs=[output_1, output_2])\n\nlearning_rate = 0.0001  # Learning rate\n\noptimizer = Adam(learning_rate=learning_rate)\n\nmodelA.compile(loss=['binary_crossentropy', 'mae'],\n              optimizer=optimizer, metrics=['accuracy', 'mae'])\n\nmodelA.summary()\n\nfrom tensorflow.keras.utils import plot_model\nplot_model(modelA, show_shapes=True)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Training\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\nhistory = modelA.fit(x=X, y=[y_gender, y_age],\n                     batch_size=32, epochs=100, validation_split=0.2, callbacks=[early_stopping])\n\n# Save model to Google Drive\nmodelA.save('/content/drive/MyDrive/ML2CW1/age_gender_A.h5')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Learning curves\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Plot results for gender classification\nacc_gender = history.history['gender_out_accuracy']\nval_acc_gender = history.history['val_gender_out_accuracy']\nloss_gender = history.history['gender_out_loss']\nval_loss_gender = history.history['val_gender_out_loss']\n\n# Plot results for age estimation\nloss_age = history.history['age_out_loss']\nval_loss_age = history.history['val_age_out_loss']\n\nepochs = range(len(acc_gender))\n\n# Plot figures for gender classification\nplt.figure(figsize=(12, 6))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs, acc_gender, 'b', label='Training Accuracy')\nplt.plot(epochs, val_acc_gender, 'r', label='Validation Accuracy')\nplt.title('Gender Classification Accuracy')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs, loss_gender, 'b', label='Training Loss')\nplt.plot(epochs, val_loss_gender, 'r', label='Validation Loss')\nplt.title('Gender Classification Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n###########################################################\n\n# Plot results for age estimation\nplt.figure(figsize=(12, 6))\n\n# Calculate MAE for age estimation (manually)\nmae_train_age = history.history['age_out_mae']\nmae_val_age = history.history['val_age_out_mae']\nloss_age = history.history['age_out_loss']\nval_loss_age = history.history['val_age_out_loss']\n\nepochs = range(len(mae_train_age))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs, mae_train_age, 'b', label='Training MAE')\nplt.plot(epochs, mae_val_age, 'r', label='Validation MAE')\nplt.title('Age Estimation MAE')\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('Mean Absolute Error')\n\n# Plot results for loss for age estimation\nplt.subplot(1, 2, 2)\n\nplt.plot(epochs, loss_age, 'b', label='Training Loss')\nplt.plot(epochs, val_loss_age, 'r', label='Validation Loss')\nplt.title('Age Estimation Loss')\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\n\nplt.tight_layout()\nplt.show()\n##########################################################\nprint(\"Validation Accuracy for Gender Classification:\", val_acc_gender[-11])\nprint(\"Validation Error for Gender Classification:\", val_loss_gender[-11])\n\nprint(\"Validation MAE for Age Estimation (10 patients before final epoch):\", mae_val_age[-11])\nprint(\"Validation Error for Age Estimation (10 patients before final epoch):\", val_loss_age[-11])\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# CNN network learning (Transfer learning)\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.models import Model\n\ndef ResNet50_transfer(input_shape=(128, 128, 3), classes=1, trainable_layers=30):\n\n    base_model = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n\n\n    for layer in base_model.layers[:-trainable_layers]:\n        layer.trainable = False\n\n    x = base_model.output\n    x = Flatten()(x)\n    x = Dense(4096, activation='relu', name='fc1')(x)\n    x = Dense(4096, activation='relu', name='fc2')(x)\n\n    output_1 = Dense(classes, activation='sigmoid', name='gender_out')(x)\n    output_2 = Dense(classes, activation='relu', name='age_out')(x)\n\n    # Combine base model with the custom top layer\n    model = Model(inputs=base_model.input, outputs=[output_1, output_2], name='modelB')\n\n    return model\n\ninput_shape = (128, 128, 3)\n\nmodelB = ResNet50_transfer(input_shape=input_shape)\n\nlearning_rate = 0.000007 # Learning rate\n\noptimizer = Adam(learning_rate=learning_rate)\n\n# Compile\nmodelB.compile(loss=['binary_crossentropy', 'mae'],\n               optimizer=optimizer,\n               metrics=['accuracy', 'mae'])\n\nmodelB.summary()\n\nfrom tensorflow.keras.utils import plot_model\nplot_model(modelB, show_shapes=True)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Training\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\nhistory = modelB.fit(x=X, y=[y_gender, y_age],\n                     batch_size=32, epochs=200, validation_split=0.2, callbacks=[early_stopping])\n\n# Save model to Google Drive\nmodelB.save('/content/drive/MyDrive/ML2CW1/age_gender_B.h5')\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Show learning curve\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Plot results for gender classification\nacc_gender = history.history['gender_out_accuracy']\nval_acc_gender = history.history['val_gender_out_accuracy']\nloss_gender = history.history['gender_out_loss']\nval_loss_gender = history.history['val_gender_out_loss']\n\n# Plot results for age estimation\nloss_age = history.history['age_out_loss']\nval_loss_age = history.history['val_age_out_loss']\n\nepochs = range(len(acc_gender))\n\n# Plot figures for gender classification\nplt.figure(figsize=(12, 6))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs, acc_gender, 'b', label='Training Accuracy')\nplt.plot(epochs, val_acc_gender, 'r', label='Validation Accuracy')\nplt.title('Gender Classification Accuracy')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs, loss_gender, 'b', label='Training Loss')\nplt.plot(epochs, val_loss_gender, 'r', label='Validation Loss')\nplt.title('Gender Classification Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n###########################################################\n\n# Plot results for age estimation\nplt.figure(figsize=(12, 6))\n\n# Calculate MAE for age estimation (manually)\nmae_train_age = history.history['age_out_mae']\nmae_val_age = history.history['val_age_out_mae']\nloss_age = history.history['age_out_loss']\nval_loss_age = history.history['val_age_out_loss']\n\nepochs = range(len(mae_train_age))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs, mae_train_age, 'b', label='Training MAE')\nplt.plot(epochs, mae_val_age, 'r', label='Validation MAE')\nplt.title('Age Estimation MAE')\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('Mean Absolute Error')\n\n# Plot results for loss for age estimation\nplt.subplot(1, 2, 2)\n\nplt.plot(epochs, loss_age, 'b', label='Training Loss')\nplt.plot(epochs, val_loss_age, 'r', label='Validation Loss')\nplt.title('Age Estimation Loss')\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\n\nplt.tight_layout()\nplt.show()\n##########################################################\n# Print validation accuracy and error for gender classification\nprint(\"Validation Accuracy for Gender Classification:\", val_acc_gender[-11])\nprint(\"Validation Error for Gender Classification:\", val_loss_gender[-11])\n\n# Print validation MAE and error for age estimation for 10 patients before final epoch\nprint(\"Validation MAE for Age Estimation:\", mae_val_age[-11])\nprint(\"Validation Error for Age Estimation:\", val_loss_age[-11])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}